{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba12d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ecadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/Users/nithinparthasarathy/Downloads/HERE_Chicago_Hackathon/here-norbel/data_chicago_hackathon_2024/cnn_model/Circle-Detection-CNN/datasets/train\"\n",
    "test_dir = \"/Users/nithinparthasarathy/Downloads/HERE_Chicago_Hackathon/here-norbel/data_chicago_hackathon_2024/cnn_model/Circle-Detection-CNN/datasets/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fbe145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE_TRAIN = 32\n",
    "BATCH_SIZE_TEST = 20\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=360,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Data Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE_TRAIN,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    shuffle=True  # Make sure shuffling is enabled\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Calculate class weights\n",
    "labels = np.array(train_generator.labels)\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "# Model Architecture with adjustments for class imbalance\n",
    "model = Sequential([\n",
    "    # First Convolutional Block\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Third Convolutional Block\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    # Use a smaller final dense layer\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    # Final layer with adjusted threshold\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile with adjusted threshold in metrics\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(threshold=0.3),  # Adjusted threshold\n",
    "        tf.keras.metrics.Precision(thresholds=0.3),\n",
    "        tf.keras.metrics.Recall(thresholds=0.3)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "# Training with class weights\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=5,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    class_weight=class_weight_dict  # Apply class weights\n",
    ")\n",
    "\n",
    "# Custom prediction function with adjusted threshold\n",
    "def predict_with_threshold(model, generator, threshold=0.3):\n",
    "    predictions = model.predict(generator)\n",
    "    return (predictions > threshold).astype(int)\n",
    "\n",
    "# Evaluation with adjusted threshold\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Important for proper evaluation\n",
    ")\n",
    "\n",
    "# Get predictions with adjusted threshold\n",
    "y_pred = predict_with_threshold(model, test_generator)\n",
    "y_true = test_generator.labels\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test precision: {precision:.4f}\")\n",
    "print(f\"Test recall: {recall:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ddbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test precision: {test_precision:.4f}\")\n",
    "print(f\"Test recall: {test_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade96331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the class labels (subdirectory names)\n",
    "class_names = os.listdir(test_dir)\n",
    "\n",
    "# Choose a random class (roundabout or no_roundabout)\n",
    "random_class = random.choice(class_names)\n",
    "\n",
    "# Get the path to the randomly selected class\n",
    "class_path = os.path.join(test_dir, random_class)\n",
    "\n",
    "# Get all image files in that class\n",
    "image_files = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Pick a random image file\n",
    "random_image_file = random.choice(image_files)\n",
    "\n",
    "# Load and display the image\n",
    "image_path = os.path.join(class_path, random_image_file)\n",
    "print(image_path)\n",
    "image = load_img(image_path, target_size=(128, 128))  # Resize to match model input size\n",
    "\n",
    "# Convert the image to an array for display purposes\n",
    "image_array = img_to_array(image)\n",
    "\n",
    "# Show the image\n",
    "plt.imshow(image_array / 255.0)  # Normalize for display\n",
    "plt.axis('off')\n",
    "plt.title(f\"Label: {random_class}\")  # Show label\n",
    "print(model.predict(image_path))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb0645",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_classes = (predictions > 0.5).astype(\"int32\")\n",
    "# print(predictions)\n",
    "\n",
    "# Print the predicted values alongside the filenames\n",
    "for filename, predicted_class in zip(test_generator.filenames, predicted_classes):\n",
    "    print(f\"Filename: {filename}, Predicted class: {'roundabout' if predicted_class == 1 else 'no roundabout'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4bb934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
